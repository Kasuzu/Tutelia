# Asistente Jur√≠dico (Tutela COL) ‚Äî RAG + Wizard

Asistente full-stack para **redactar acciones de tutela en Colombia** con apoyo de IA y **RAG** (b√∫squeda sem√°ntica sobre normas/sentencias). Incluye un **wizard** que gu√≠a el diligenciamiento, **persistencia en SQLite**, **mejoras autom√°ticas de texto**, **exportaci√≥n a DOCX/JSON** y compatibilidad con **modelos LLM locales** v√≠a **LM Studio** (p. ej., modelos **peque√±os** tipo *Gemma 3* / *GEMA3*, que permiten ejecutar en PCs modestos e incluso mini‚ÄëPCs). Tambi√©n puedes conectarlo a un endpoint remoto (online).

<p align="left">
  <a href="https://www.python.org/"><img alt="Python" src="https://img.shields.io/badge/Python-3.10‚Äì3.12-blue.svg"></a>
  <a href="https://fastapi.tiangolo.com/"><img alt="FastAPI" src="https://img.shields.io/badge/FastAPI-1.x-009688.svg"></a>
  <img alt="License" src="https://img.shields.io/badge/License-MIT-green.svg">
  <img alt="Status" src="https://img.shields.io/badge/Status-Active-success.svg">
</p>

---

## Tabla de contenidos

- [¬øPara qu√© sirve en la vida real?](#para-qu√©-sirve-en-la-vida-real)
- [Caracter√≠sticas](#caracter√≠sticas)
- [Arquitectura](#arquitectura)
- [Requisitos](#requisitos)
- [Instalaci√≥n r√°pida (5 minutos)](#instalaci√≥n-r√°pida-5-minutos)
- [Instalaci√≥n detallada](#instalaci√≥n-detallada)
  - [1) Crear y activar entorno](#1-crear-y-activar-entorno)
  - [2) Instalar dependencias](#2-instalar-dependencias)
  - [3) Configurar el LLM (LM Studio local o endpoint online)](#3-configurar-el-llm-lm-studio-local-o-endpoint-online)
  - [4) Embeddings y RAG](#4-embeddings-y-rag)
  - [5) Ingesta de documentos](#5-ingesta-de-documentos)
  - [6) Levantar el servidor](#6-levantar-el-servidor)
- [Flujo de uso](#flujo-de-uso)
- [Variables de entorno (.env de ejemplo)](#variables-de-entorno-env-de-ejemplo)
- [Endpoints principales](#endpoints-principales)
- [Exportaci√≥n](#exportaci√≥n)
- [Ejecutar desde dispositivos modestos o m√≥viles](#ejecutar-desde-dispositivos-modestos-o-m√≥viles)
- [Soluci√≥n de problemas](#soluci√≥n-de-problemas)
- [Seguridad y privacidad](#seguridad-y-privacidad)
- [FAQ](#faq)
- [Roadmap](#roadmap)
- [Licencia y descargos](#licencia-y-descargos)

---

## ¬øPara qu√© sirve en la vida real?

La **acci√≥n de tutela** es un **mecanismo constitucional** (art. 86) para la protecci√≥n inmediata de **derechos fundamentales**. **No se requiere abogado** para interponerla: **cualquier persona** puede presentar su tutela. Puede amparar derechos **directamente** o por **conexidad** cuando un derecho no fundamental est√° √≠ntimamente ligado a uno fundamental.

Este software permite que **cualquier persona** elabore, **presente y corrija** su tutela gracias a la **exportaci√≥n a Word editable (.docx)** y a un **flujo guiado** que ordena hechos, pretensiones, pruebas y fundamentos. Al ejecutarse **en local**, con **bajos requisitos** (modelos peque√±os como *Gemma 3/GEMA3* en LM Studio), favorece el **acceso a la justicia** en contextos con conectividad limitada o equipos modestos.

En la pr√°ctica, abogadas/os y ciudadan√≠a enfrentan tres retos:
1. **Tiempo**: redactar bajo presi√≥n (plazos cortos).
2. **Calidad**: articular hechos, derechos y fundamentos jur√≠dicos sin omitir piezas clave.
3. **Fuentes**: ubicar precedentes/referencias relevantes para el caso concreto.

Este proyecto ayuda a **estructurar** y **mejorar** el escrito de tutela, sugiere **derechos vulnerados**, arma **fundamentos jur√≠dicos** (incluida una secci√≥n de **fundamentos de derecho v√≠a RAG** con fuentes reales que cargues) y genera una **referencia (REF)** estandarizada. Todo con un flujo guiado, repetible y auditable.

**Ejes de Ciberpaz que inspiran esta hackat√≥n (origen del programa):**
- **Derechos Digitales y Derechos de Autor**
- **Herramientas TIC para el trabajo incluyente y seguro**
- **Libertades Tecnol√≥gicas**
- **Diversidad e inclusi√≥n digital**
- **Seguridad y confianza digital**
- **Tecnolog√≠a y Medio Ambiente**

> **Ejemplos de uso real**  
> - Personas a las que **no responden peticiones** en t√©rminos legales.  
> - **Demoras en entrega de tratamientos** o servicios de salud esenciales.  
> - **Barreras administrativas** que afectan derechos de ni√±os, poblaci√≥n vulnerable o trabajadores.  
> - Necesidad de **documentar pruebas y anexos** de manera clara y normalizada.


---

## Caracter√≠sticas

- **Wizard de Tutela** con flujo realista (usuario escribe; IA mejora).  
  *Ventajas:* gu√≠a paso a paso, reduce la curva de aprendizaje, **minimiza errores de forma** y **uniformiza** los escritos.

- **RAG** con **Chroma** + embeddings HF para citar normas/sentencias (t√∫ controlas el corpus).  
  *Ventajas:* **citas verificables**, trabajo **privado/offline** y control total sobre fuentes. Puedes **alimentarlo con nuevos documentos (PDF/DOCX/TXT/MD)** en `./docs` y reindexar en minutos. **Mientras m√°s corpus tengas, mejor cobertura y precisi√≥n contextual** obtendr√°s.

- **Mejoras autom√°ticas** al guardar en **Hechos**, **Pretensiones** (con sugerencias no-econ√≥micas) y **Pruebas y Anexos**.  
  *Ventajas:* **ahorra tiempo**, estandariza redacci√≥n, sugiere pretensiones v√°lidas y **normaliza pruebas/anexos** (claridad probatoria).


- **Secciones autocompletadas**: Intro, Notificaciones y Firmas desde datos de partes.  
  *Ventajas:* elimina tecleo repetitivo, **reduce inconsistencias** (nombres/direcciones) y agiliza notificaciones y firmas.

- **Persistencia** en **SQLite** (casos, partes, secciones, versiones).  
  *Ventajas:* base **portable** (archivo `.db`), **cero** instalaci√≥n de servidor, versiones de secciones y backups simples.

- **Exportaci√≥n** a **Word (.docx)** y **bundle .json** del caso.  
  *Ventajas:* **editable por cualquiera** (Word), **interoperable** (JSON), facilita revisi√≥n y control de cambios.

- **Configurable por `.env`**.  
  *Ventajas:* cambia **modelo LLM**, temperatura, embeddings, `TOP_K`, rutas y modos **sin tocar c√≥digo** (dev/prod).

- **Compatibilidad LLM local** (LM Studio; modelos peque√±os tipo **Gemma 3/GEMA3**) y **funcionamiento online** contra un endpoint OpenAI-compatible.  
  *Ventajas:* **barrera de hardware baja** y **privacidad local**, o **escalamiento** en la nube; funciona en PCs modestos y clientes m√≥viles v√≠a navegador.



---

## Arquitectura

- **Backend:** FastAPI (endpoints `/advisor/*` y `/wizard/*`).
- **IA / LLM:** cualquier LLM comptaible con el servidor de LM Studio.
- **RAG:** **ChromaDB** con embeddings de **Hugging Face** (p. ej., `intfloat/multilingual-e5-small`).
- **Archivos clave:**
  - `app.py` ‚Äî enrutamiento y p√°ginas r√°pidas.
  - `tutela.py` ‚Äî l√≥gica del Wizard (CRUD, mejoras IA, cadena, compose/export).
  - `advisor.py` ‚Äî asesor jur√≠dico con RAG (respuestas + citas).
  - `ingest.py` ‚Äî ingesta de PDFs/DOCX/TXT/MD al √≠ndice vectorial.
  - `reset.py` ‚Äî limpia el √≠ndice (`PERSIST_DIR`).

---

## Requisitos

- **Python** 3.10‚Äì3.12
- **Git** (opcional, para clonar)
- **LM Studio** (si usar√°s **LLM local**) o un **endpoint online** OpenAI‚Äëcompatible
- **Build tools** b√°sicos (Windows: *Build Tools for Visual Studio* si alguna lib lo requiere)

---

## Instalaci√≥n r√°pida (5 minutos)

```bash
# 1) Clonar (o copia local)
git clone https://github.com/tu-usuario/tu-repo-tutela.git
cd tu-repo-tutela

# 2) (opcional) Crear venv
python -m venv env
# Linux/macOS:
source env/bin/activate
# Windows (PowerShell):
.\env\Scripts\Activate.ps1

# 3) Instalar deps
pip install -r requirements.txt

# 4) Configurar .env (ver ejemplo abajo)

# 5) Ingestar tus fuentes (RAG)
python ingest.py

# 6) Levantar
uvicorn app:app --reload
```

Navega a: `http://127.0.0.1:8000` ‚Üí p√°ginas r√°pidas: **/tutela**, **/asesor**.

---

## Instalaci√≥n detallada

### 1) Crear y activar entorno

```bash
python -m venv env
# Linux/macOS:
source env/bin/activate
# Windows:
.\env\Scripts\Activate.ps1
```

### 2) Instalar dependencias

pip install -r requirements.txt

### 3) Configurar el LLM (LM Studio local o endpoint online)

**LM Studio (local):**
1. **Descarga e instala LM Studio** desde üëâ https://lmstudio.ai/  
2. Abre LM Studio y **habilita las opciones de desarrollador** (Settings ‚Üí *Developer* / *Advanced* ‚Üí Enable Developer features).  
3. En la pesta√±a **Models**, **descarga el modelo ‚ÄúGEMA‚Äù** (p. ej., *Gemma 3/GEMA3* u otro equivalente ligero).  
   - Si decides usar **otro modelo**, **solo cambia su nombre** en el archivo `.env` (clave `LLM_MODEL`).  
4. En **Settings ‚Üí Developer**, **activa ‚ÄúLocal Server (OpenAI compatible)‚Äù y selecciona el modelo a cargar/servir** en el desplegable del servidor. Verifica que el estado est√© en **Running** y que aparezca **Reachable at: `http://127.0.0.1:1234`**.  
5. Configura tu `.env` (aseg√∫rate de que `LLM_MODEL` coincida con el nombre/alias del modelo cargado en LM Studio):
   ```ini
   OPENAI_API_BASE=http://127.0.0.1:1234/v1
   OPENAI_API_KEY=lm-studio        # valor dummy aceptado por LM Studio
   LLM_MODEL=local/gemma-3         # cambia aqu√≠ si usas otro modelo (p. ej., local/gema-3)
   LLM_TEMPERATURE=0.2


### 4) Embeddings y RAG

En `.env` puedes elegir embeddings (por defecto recomendados por su balance calidad/velocidad):

```ini
EMBEDDING_MODEL=intfloat/multilingual-e5-small
PERSIST_DIR=./chroma
TOP_K=3
DOCS_DIR=./docs
CHUNK_SIZE=600
```

### 5) Ingesta de documentos

Coloca tus **PDF/DOCX/TXT/MD** en `./docs` y corre:

```bash
python ingest.py
```

Para reiniciar desde cero:

```bash
python reset.py
python ingest.py
```

### 6) Levantar el servidor

```bash
uvicorn app:app --reload
```
- Salud: `GET /healthz`
- UI r√°pida: `/tutela` (wizard), `/asesor` (chat con RAG)

---

## Flujo de uso

1. **Crea un caso** en el Wizard.
2. **Registra partes** (accionantes/accionados) ‚Üí el sistema arma **Intro**, **Notificaciones** y **Firmas**.
3. **Escribe Hechos / Pretensiones / Pruebas y Anexos** ‚Üí al guardar, la IA **mejora** y normaliza.
4. Ejecuta la **cadena jur√≠dica** (opcional en un paso):  
   **Derechos vulnerados ‚Üí Fundamentos jur√≠dicos ‚Üí Fundamentos de derecho (RAG) ‚Üí REF**.
5. **Comp√≥n** el texto final (endpoint de compose) o **exporta** a **.docx** y **.json**.
6. Revisa el **asesor** (/asesor) para dudas puntuales con **citas** de tu corpus.

---

## Variables de entorno (.env de ejemplo)

```ini
# === LLM local v√≠a LM Studio ===
OPENAI_API_BASE=http://127.0.0.1:1234/v1
OPENAI_API_KEY=lm-studio
LLM_MODEL=local/gemma-3
LLM_TEMPERATURE=0.2

# === Salida del modelo ===
MAX_TOKENS_STEP=1024
LLM_MAX_TOKENS=4096

# === Embeddings (HuggingFace) ===
EMBEDDING_MODEL=intfloat/multilingual-e5-small

# === RAG (retrieval) ===
TOP_K=3

# === Vector DB (Chroma) ===
PERSIST_DIR=./chroma

# === Ingesta de documentos ===
DOCS_DIR=./docs
CHUNK_SIZE=600

# === Modo estricto del asesor (si no hay fuentes, no responde) ===
STRICT_CONTEXT=0
```

> **Nota:** si el proveedor remoto requiere otro nombre de modelo o token, ajusta `LLM_MODEL` y `OPENAI_API_KEY` seg√∫n su documentaci√≥n.

---

## Endpoints principales

- **Wizard**
  - `POST /wizard/case` ‚Äî crea caso
  - `POST /wizard/case/{id}/party` ‚Äî agrega/edita partes (auto: Intro/Notif/Firmas)
  - `POST /wizard/case/{id}/section/{name}` ‚Äî guarda secci√≥n y mejora IA (seg√∫n `name`)
  - `POST /wizard/case/{id}/run-pipeline` ‚Äî ejecuta la cadena jur√≠dica completa
  - `GET /wizard/case/{id}/compose-final` ‚Äî devuelve texto final concatenado
  - `POST /wizard/case/{id}/export-docx` ‚Äî genera `.docx` (y `.json` auxiliar)

- **Advisor (RAG)**
  - `POST /advisor/start` ‚Äî inicia sesi√≥n de asesor√≠a
  - `POST /advisor/answer` ‚Äî responde con **citas** (y puntajes, si aplica)

---

## Exportaci√≥n

- **DOCX**: formato jur√≠dico (encabezado, t√≠tulos, numeraciones, bloque de firmas).
- **JSON**: bundle estructurado del caso para interoperabilidad (editores/servicios externos).

---

## Ejecutar desde dispositivos modestos o m√≥viles

- **Hardware modesto**: con **LM Studio** + modelos **peque√±os** (p. ej., *Gemma 3/GEMA3* cuantizada), el backend corre fluido en laptops de gama media/baja.
- **Acceso desde celular**: basta abrir la URL del servidor en el navegador del tel√©fono (misma red). El modelo puede correr:
  - **Local** en tu PC/mini‚ÄëPC (LM Studio) y el **celular solo consume la UI**.
  - **Online** en un servidor remoto  (tu tel√©fono act√∫a como cliente).

> Ejecutar la **inferencia del LLM directamente en el tel√©fono** depender√° de apps/soporte espec√≠fico. La v√≠a simple: correr el LLM en un PC y usar el **celular como cliente**.

---



## Seguridad y privacidad

- T√∫ controlas el **corpus** del RAG (`./docs`).
- Con **LLM local**, tus textos no salen de tu equipo. Con endpoint online, revisa t√©rminos del proveedor.
- Usa `STRICT_CONTEXT=1` si quieres bloquear respuestas sin fuentes en el √≠ndice.

---

## FAQ

**¬øNecesito Internet?**  
No, si usas **LM Studio local** + tu corpus. Internet solo para descargar el modelo la primera vez.

**¬øPuedo usar otro LLM?**  
S√≠. Cualquier LLM es  **compatible**. Ajusta `OPENAI_API_BASE`, `OPENAI_API_KEY` y `LLM_MODEL`.

**¬øQu√© documentos admite la ingesta?**  
PDF, DOCX, TXT y MD. Se trocean y se indexan en Chroma con metadatos de origen/p√°gina.

**¬øC√≥mo reinicio el √≠ndice?**  
`python reset.py` y luego `python ingest.py`.

---

## Roadmap

- Validadores de consistencia entre **Hechos ‚Üê‚Üí Pretensiones**.
- Plantillas DOCX personalizables por despacho/distrito.
- Panel de citas con **previsualizaci√≥n** (PDF.js) y export a **.bib**.
- Modo **colaborativo** (multiusuario) con autenticaci√≥n.

---

## Licencia y descargos

Este software es **apoyo informativo** para la **redacci√≥n de tutelas**; **no sustituye** asesor√≠a legal profesional. √ösalo bajo tu responsabilidad y valida siempre la normativa vigente y precedentes aplicables.  


---

> ¬øSugerencia? Abre un **issue** o env√≠a un **PR**. ¬°Contribuciones bienvenidas!
